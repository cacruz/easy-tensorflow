{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to TensorBoard \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/easy-tensorflow/easy-tensorflow/blob/master/1_TensorFlow_Basics/Tutorials/3_Introduction_to_Tensorboard.ipynb)\n",
    "\n",
    "In the first post, we discussed the advantages of TensorFlow. They were mainly flexibility and visualization. Imagine if you can visualize whats happening in the code (in this case code represents the computational graph that we create for a model), it would be so convenient to deeply understand and observe the inner workings of the graph. Not just that, it also helps in fixing things that are not working the way they should. TensorFlow provides a way to do just that using TensorBoard!\n",
    "\n",
    "__TensorBoard__ is a visualization software that comes with any standard TensorFlow installation. In Google’s words: “The computations you'll use TensorFlow for many things (like training a massive deep neural network) and they can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, we've included a suite of visualization tools called TensorBoard.”\n",
    "\n",
    "TensorFlow programs can range from a very simple to super complex problems (using thousands of computations), and they all have two basic components, Operations, and Tensors. As explained in the previous tutorials, the idea is that you create a model that consists of a set of operations, feed the data into the model and the tensors will flow between the operations until you get an output tensor i.e., your result. TensorBoard provides us with a suite of web applications that help us to inspect and understand the TensorFlow runs and graphs. Currently, it provides five types of visualizations: scalars, images, audio, histograms, and graphs.\n",
    "\n",
    "When fully configured, TensorBoard window will look something like:\n",
    "\n",
    "<img src=\"files/files/3_1.png\" width=\"500\" height=\"1000\">\n",
    "\n",
    "\n",
    "___Fig. 1. ___ TensorBoard appearance\n",
    "\n",
    "\n",
    "TensorBoard was created as a way to help us understand the flow of tensors in your model so that we can debug and optimize it. It is generally used for two main purposes:\n",
    "\n",
    "__1. Visualizing the Graph__\n",
    "\n",
    "__2. Writing Summaries to Visualize Learning__\n",
    "\n",
    "We'll cover the main usages of TensorBoard in this tutorial. Learning to use TensorBoard early and often will make working with TensorFlow much more enjoyable and productive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualizing the Graph\n",
    "\n",
    "While powerful, TensorFlow computation graphs can become extremely complicated. Visualizing the graph can help us understand and debug it. Here's an example of the visualization at work from TensorFlow website.\n",
    "\n",
    "<img src=\"files/files/3_2.gif\" width=\"500\" height=\"1000\" >\n",
    " \n",
    "___Fig. 2. ___ Visualization of a TensorFlow graph (Source: TensorFlow website)\n",
    "\n",
    "To make our TensorFlow code __TensorBoard-activated__, we need to add some lines of code. This will export the TensorFlow operations into a file, called __event file__ (or event log file). TensorBoard is able to read this file and give some insights of the model graph and its performance.\n",
    "\n",
    "Now let's write a simple TensorFlow code and visualize its computational graph with TensorBoard.\n",
    "\n",
    "### Example 1:\n",
    "Let's create two constants and add them together. As we say in the previous tutorial, we can create a `tf.function` to create our graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create tf.function\n",
    "@tf.function\n",
    "def simple_add(a, b):\n",
    "    # create the graph\n",
    "    c = tf.add(a, b, name=\"addition\")\n",
    "    return c\n",
    "\n",
    "a = tf.constant(2, name=\"a\")\n",
    "b = tf.constant(3, name=\"b\")\n",
    "\n",
    "# execute the function\n",
    "c = simple_add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the graph with TensorBoard, we need to write log. To write event files, we first need to create a __writer__ for those logs, using the following template code:\n",
    "\n",
    "```python\n",
    "writer = tf.summary.FileWriter([logdir], [graph])\n",
    "```\n",
    "\n",
    "where\n",
    "\n",
    "__[logdir]__ is the folder where we want to store those log files. We can also choose [logdir] to be something meaningful such as './graphs'.\n",
    "\n",
    "__[graph]__ is the graph of the function we're working on. We can get the graph by using the following code:\n",
    "```python\n",
    "tf_function.get_concrete_function(*args).graph\n",
    "```\n",
    "For example, in our case, we can get the graph by:\n",
    "```python\n",
    "simple_add.get_concrete_function(a, b).graph\n",
    "```\n",
    "\n",
    "Let's add the writer to the first example and visualize the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs saved to: ./graphs\n"
     ]
    }
   ],
   "source": [
    "# creating the writer out of the session\n",
    "logdir = './graphs'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Write the traced graph to TensorBoard\n",
    "with writer.as_default():\n",
    "    tf.summary.graph(simple_add.get_concrete_function(a, b).graph)\n",
    "    writer.flush()\n",
    "\n",
    "print(f\"TensorBoard logs saved to: {logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will create  a directory inside your current directory (beside your Python code file) which contains the __event file__.\n",
    "\n",
    "<img src=\"files/files/3_3.png\" width=\"300\" height=\"600\" >\n",
    "\n",
    "___Fig. 3. ___ Created directory which contains the event file\n",
    "\n",
    "\n",
    "Next, to visualize the graph, we need to go to Terminal and make sure that the present working directory is the same as where we ran our Python code. For example, here we can switch to the directory using the commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd ~/Desktop/tensorboard\n",
    "tensorboard --logdir=\"./graphs\" --host localhost --port 6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace './graphs' with the name of the directory in case you choose to name it something else. This will generate a link on the command line. Control click (ctrl+left) the link to open the TensorBoard window, TensorBoard uses the web browser to show us the visualizations (or simply copy it into your browser or just open your browser and go to http://localhost:6006/). The link will direct us to the TensorBoard page, it should look similar to:\n",
    "\n",
    "<img src=\"files/files/3_4.png\" width=\"500\" height=\"1000\" >\n",
    "\n",
    "___Fig. 4. ___ TensorBoard page visualizing the graph generated in Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you are running the code in a Jupyter notebook, you can use the following code to open TensorBoard in a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6e10d678e799bfd7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6e10d678e799bfd7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the link to open TensorBoard in a new window: http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"./graphs\" --host localhost --port 6006\n",
    "print(\"Click on the link to open TensorBoard in a new window: http://localhost:6006/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Note:__ If we run our code several times with the same [logdir], multiple event files will be generated in our [logdir]. TF will only show the latest version of the graph and display the warning of multiple event files. The warning can be removed by deleting the event files that we no longer need or else we can save them in a different [logdir] folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Summaries to Visualize Learning\n",
    "\n",
    "So far we only focused on how to visualize the graph in TensorBoard. Remember the other types of visualizations mentioned in the earlier part of the post that TensorBoard provides (scalars, images and histograms). In this part, we are going to use a special operation called __summary__ to visualize the model parameters (like weights and biases of a neural network), metrics (like loss or accuracy value), and images (like input images to a network). \n",
    "\n",
    "__Summary__ is a special operation TensorBoard that takes in a regular tensor and outputs the summarized data to your disk (i.e. in the event file). There are several types of summaries in TensorFlow ([read more](https://www.tensorflow.org/api_docs/python/tf/summary)), but we will focus on the following three types in this post:\n",
    "\n",
    "__1. tf.summary.scalar:__ used to write a single scalar-valued tensor (like a classification loss or accuracy value)\n",
    "\n",
    "__2. tf.summary.histogram:__ used to plot histogram of all the values of a non-scalar tensor (can be used to visualize weight or bias matrices of a neural network)\n",
    "\n",
    "__3. tf.summary.image:__ used to plot images (like input images of a network, or generated output images of an autoencoder or a GAN)\n",
    "\n",
    "In the following sections, let's go through each of the above mentioned summary types in more detail.\n",
    "\n",
    "\n",
    "### 2.1. tf.summary.scalar:\n",
    "It's for writing the values of a scalar tensor that changes over time or iterations. In the case of neural networks (say a simple network for classification task), it's usually used to monitor the changes of loss function or classification accuracy.\n",
    "\n",
    "Let's run a simple example to understand the point.\n",
    "\n",
    "### Example 2:\n",
    "Randomly pick 100 values from a standard Normal distribution, _N(0, 1)_, and plot them one after the other.\n",
    "\n",
    "One way to do so is to create a scalar variable and write its value to the __summary__ using __tf.summary.scalar__. We can then write the summary to the disk using a __tf.summary.FileWriter__. The code is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summaries\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create a summary writer to write the summaries to disk\n",
    "summary_write = tf.summary.create_file_writer('./summaries_scalar')\n",
    "\n",
    "with summary_write.as_default():\n",
    "    for step in range(100):\n",
    "        # create a random scalar variable\n",
    "        random_scalar = tf.random.normal([], mean=0, stddev=1)\n",
    "        \n",
    "        # write the scalar summary\n",
    "        tf.summary.scalar('Random_scalar', random_scalar, step=step)\n",
    "        \n",
    "print('Done writing the summaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull up TensorBoard and checkout the result. Like before, you need to open terminal and type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "tensorboard --logdir=\"./summaries_scalar\" --host localhost --port 6007\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Note:__ Since we used port 6006 in the previous example, we need to use a different port (6007) for this example.\n",
    "\n",
    "If you are running the code in a Jupyter notebook, you can use the following code to open TensorBoard in a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-37cc8182d4aa812\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-37cc8182d4aa812\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the link to open TensorBoard in a new window: http://localhost:6007/\n"
     ]
    }
   ],
   "source": [
    "# Reload the extension if it was already loaded from the previous example\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"./summaries_scalar\" --host localhost --port 6007\n",
    "print(\"Click on the link to open TensorBoard in a new window: http://localhost:6007/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here _\"./summaries_scalar\"_ is the name of the directory we saved the event file to. In TensorBoard, we find a new tab named __\"scalars\"__. The whole window looks like:\n",
    "\n",
    "<img src=\"files/files/3_6.png\" width=\"500\" height=\"1000\" >\n",
    "\n",
    "___Fig. 6. ___ TensorBoard page visualizing the written scalar summary.\n",
    "\n",
    "In the figure, the x-axis and y-axis shows the 100 steps and the corresponding values (random values from a standard normal distribution) of the variable respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. tf.summary.histogram:\n",
    "\n",
    "Histogram comes in handy if we want to observe the change of a value over time or iterations. It's used for plotting the histogram of the values of a non-scalar tensor. This provides us a view of how the histogram (and the distribution) of the tensor values change over time or iterations. In the case of neural networks, it's commonly used to monitor the changes of weight and biase distributions. It's very useful in detecting irregular behavior of the network parameters (for example, when our weights explode or shrink abnormally). \n",
    "\n",
    "### Example 3:\n",
    "We will create a scalar and matrix of size 30x40, whose entries come from a standard normal distribution. Initialize the variables 100 times and plot their distribution over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summary histograms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create a summary writer to write the summaries to disk\n",
    "summary_write = tf.summary.create_file_writer('./summaries_histogram')\n",
    "\n",
    "with summary_write.as_default():\n",
    "    for step in range(100):\n",
    "        \n",
    "        # create a random matrix variable\n",
    "        random_matrix = tf.random.normal([30, 40], mean=0, stddev=1)\n",
    "        \n",
    "        # write the histogram summary\n",
    "        tf.summary.histogram('Random_matrix', random_matrix, step=step)\n",
    "        \n",
    "print('Done writing the summary histograms')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, open TensorBoard and checkout the result. Like before, you need to open terminal and type:\n",
    "```bash\n",
    "tensorboard --logdir=\"./summaries_histogram\" --host localhost --port 6008\n",
    "```\n",
    "Or if you are running the code in a Jupyter notebook, you can use the following code to open TensorBoard in a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5e708479bea5968c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5e708479bea5968c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the link to open TensorBoard in a new window: http://localhost:6008/\n"
     ]
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"./summaries_histogram\" --host localhost --port 6008\n",
    "print(\"Click on the link to open TensorBoard in a new window: http://localhost:6008/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorBoard, two new tabs are added to the top menu: \"Distributions\" and \"Histograms\". The results will be as follows:\n",
    "\n",
    "<img src=\"files/files/3_7.png\">\n",
    "\n",
    "___Fig. 7. ___ (a) scalar summary, (b) distribution and (c) histogram of the values of the 2D-tensor over 100 steps\n",
    "\n",
    "\n",
    "In the figure, the \"Distributions\" tab contains a plot that shows the distribution of the values of the tensor (y-axis) through steps (x-axis). You might ask what are the light and dark colors? \n",
    "\n",
    "The answer is that each line on the chart represents a percentile in the distribution over the data. For example, the bottom line (the very light one) shows how the minimum value has changed over time, and the line in the middle shows how the median has changed. Reading from top to bottom, the lines have the following meaning: [maximum, 93%, 84%, 69%, 50%, 31%, 16%, 7%, minimum]\n",
    "\n",
    "These percentiles can also be viewed as standard deviation boundaries on a normal distribution: [maximum, μ+1.5σ, μ+σ, μ+0.5σ, μ, μ-0.5σ, μ-σ, μ-1.5σ, minimum] so that the colored regions, read from inside to outside, have widths [σ, 2σ, 3σ] respectively.\n",
    "\n",
    "Similarly, in the histogram panel, each chart shows temporal \"slices\" of data, where each slice is a histogram of the tensor at a given step. It's organized with the oldest timestep in the back, and the most recent timestep in front.\n",
    "\n",
    "You can easily monitor the values on the histograms at any step. Just move your cursor on the plot and see the x-y values on the histograms (Fig8 (a)). You can also change the Histogram Mode from \"offset\" to \"overlay\" (see Fig. 8- (b)) to see the histograms overlaid with one another.\n",
    "\n",
    "\n",
    "<img src=\"files/files/3_8.png\">\n",
    "\n",
    "___Fig. 8. ___ (a) monitor values on the histograms, (b) overlayed histograms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. tf.summary.image:\n",
    "As the name implies, this type of summary is used for writing and visualizing tensors as images. In the case of neural networks, this is usually used for tracking the images that are either fed to the network (say in each batch) or the images generated in the output (such as the reconstructed images in an autoencoder; or the fake images made by the generator model of a Generative Adverserial Network). However, in general, this can be used for plotting any tensor. For example, we can visualize a weight matrix of size 30x40 as an image of 30x40 pixels.\n",
    "\n",
    "An image summary can be created using:\n",
    "\n",
    "```python\n",
    "tf.summary.image(name, data, step=None, max_outputs=3)\n",
    "```\n",
    "\n",
    "Where `name` is the name for the generated node (i.e. operation), `data` is the desired tensor to be written as an image summary (we will talk about its shape shortly), `step` is the step number for this summary and `max_outputs` is the maximum number images to be emitted per step.\n",
    "\n",
    "The `data` that we feed to tf.summary.image must be a 4-D tensor of shape `[batch_size, height, width, channels]` where batch_size is the number of images in the batch, the height and width determine the size of the image and finally, the channels are:\n",
    "1: for Grayscale images.\n",
    "3: for RGB (i.e. color) images.\n",
    "4: for RGBA images (where A stands for alpha; see [RGBA](https://en.wikipedia.org/wiki/RGBA_color_space)).\n",
    "\n",
    "Let's look at a very simple example to get the underlying idea.\n",
    "\n",
    "### Example 4:\n",
    "Let's create two random batches of grayscale and color images and plot them as images in TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summary images\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create a summary writer to write the summaries to disk\n",
    "summary_write = tf.summary.create_file_writer('./summaries_image')\n",
    "\n",
    "with summary_write.as_default():\n",
    "    for step in range(100):\n",
    "        \n",
    "        # create a random grayscale image\n",
    "        random_batch_gray = tf.random.normal([3, 10, 10, 1])\n",
    "        \n",
    "        # create a random color image\n",
    "        random_batch_color = tf.random.normal([5, 10, 10, 3])\n",
    "        \n",
    "        # write the image summaries\n",
    "        tf.summary.image('grayscale_images', random_batch_gray, step=step)\n",
    "        tf.summary.image('color_images', random_batch_color, step=step, max_outputs=5)\n",
    "        \n",
    "print('Done writing the summary images')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open TensorBoard like before and switch to __IMAGES__ tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d5f250d47c623b7d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d5f250d47c623b7d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the link to open TensorBoard in a new window: http://localhost:6009/\n"
     ]
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"./summaries_image\" --host localhost --port 6009\n",
    "print(\"Click on the link to open TensorBoard in a new window: http://localhost:6009/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images should be something similar to:\n",
    "<img src=\"files/files/3_9.png\">\n",
    "\n",
    "___Fig. 9. ___ generated images in TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly add any other image of any size to our summaries and plot them in TensorBoard. We'll see more of such summaries in our next tutorials. You can create a Linear Classifier and use TensorBoard using our [Linear Classifier with TensorBoard](https://github.com/easy-tensorflow/easy-tensorflow/blob/master/2_Linear_Classifier/Tutorials/1_Linear_Classifier.ipynb) post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Tips on running TensorBoard in Jupyter Notebook\n",
    "If you are running the code in a Jupyter notebook, you can list the TensorBoard instances running in the background using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6007: logdir ./summaries_scalar (started 0:00:07 ago; pid 18096)\n",
      "  - port 6006: logdir ./graphs (started 0:00:09 ago; pid 18576)\n",
      "  - port 6008: logdir ./summaries_histogram (started 0:00:04 ago; pid 19220)\n",
      "  - port 6009: logdir ./summaries_image (started 0:00:01 ago; pid 6840)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also display the TensorBoard in the notebook itself using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir ./graphs (started 0:00:09 ago; port 6006, pid 18576).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87a6c428486635ac\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87a6c428486635ac\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete the TensorBoard instance by deleting the content of the following directory:\n",
    "```bash\n",
    "# in Windows\n",
    "C:\\Users\\<UserName>\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "\n",
    "# in Linux\n",
    "/tmp/.tensorboard-info\n",
    "\n",
    "# in Mac\n",
    "/private/var/folders/<random>/T/.tensorboard-info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this post has helped you to understand the basic key features of __TensorBoard__. Thank you so much for reading! If you have any questions, feel free to leave a comment in our [webpage](http://www.easy-tensorflow.com/basics/introduction-to-tensorboard). You can also send us feedback through the [__contacts__](http://www.easy-tensorflow.com/contacts) page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
